{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOF8vFCTO+xBl3Ewb3bmaTx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import random\n","import torch\n","from transformers import BertTokenizer, BertForMaskedLM\n","from nltk.corpus import wordnet as wn\n","import nltk"],"metadata":{"id":"GmGCCC_hYRpv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nltk.download('wordnet')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iZin9Np5YTYA","executionInfo":{"status":"ok","timestamp":1717758471523,"user_tz":-300,"elapsed":12,"user":{"displayName":"MUHAMMAD AHMED","userId":"14899745095089662324"}},"outputId":"02c5c063-9bcf-41e4-e75a-4fd68a2e15be"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aDd4SaqoXiVS"},"outputs":[],"source":["class QuestionGenerator:\n","    def __init__(self, passage, model_name='bert-base-uncased'):\n","        self.tokenizer = BertTokenizer.from_pretrained(model_name)\n","        self.model = BertForMaskedLM.from_pretrained(model_name)\n","        self.passage = passage\n","\n","    def generate_fill_in_the_blanks(self, sentences, num_questions):\n","        fill_in_the_blanks_dict = {}\n","        used_sentences = set()\n","        while len(fill_in_the_blanks_dict) < num_questions:\n","            selected_sentence = random.choice(sentences)\n","            if selected_sentence in used_sentences:\n","                continue\n","            used_sentences.add(selected_sentence)\n","            if not selected_sentence.endswith('.'):\n","                selected_sentence += '.'\n","            tokens = self.tokenizer.tokenize(selected_sentence)\n","            masked_idx = random.choice([i for i, token in enumerate(tokens) if token.isalpha()])\n","            masked_word = tokens[masked_idx]\n","            tokens[masked_idx] = '[MASK]'\n","            input_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n","            input_ids = torch.tensor([input_ids])\n","            with torch.no_grad():\n","                outputs = self.model(input_ids)\n","                predictions = outputs.logits\n","            masked_idx_tensor = torch.tensor([masked_idx])\n","            predicted_token_ids = torch.topk(predictions[0, masked_idx_tensor], 5).indices[0].tolist()\n","            predicted_tokens = self.tokenizer.convert_ids_to_tokens(predicted_token_ids)\n","            sentence_with_blank = self.tokenizer.convert_tokens_to_string(tokens).replace('[MASK]', '***')\n","            fill_in_the_blanks_dict[masked_word] = sentence_with_blank\n","        return fill_in_the_blanks_dict\n","\n","    def get_random_word(self):\n","        synsets = list(wn.all_synsets())\n","        random_synset = random.choice(synsets)\n","        return random_synset.lemmas()[0].name()\n","\n","    def generate_mcqs(self, sentences, num_questions):\n","        mcq_questions_list = []\n","        used_sentences = set()\n","        while len(mcq_questions_list) < num_questions:\n","            selected_sentence = random.choice(sentences)\n","            if selected_sentence in used_sentences:\n","                continue\n","            used_sentences.add(selected_sentence)\n","            if not selected_sentence.endswith('.'):\n","                selected_sentence += '.'\n","            tokens = self.tokenizer.tokenize(selected_sentence)\n","            masked_idx = random.choice([i for i, token in enumerate(tokens) if token.isalpha()])\n","            masked_word = tokens[masked_idx]\n","            tokens[masked_idx] = '[MASK]'\n","            input_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n","            input_ids = torch.tensor([input_ids])\n","            with torch.no_grad():\n","                outputs = self.model(input_ids)\n","                predictions = outputs.logits\n","            masked_idx_tensor = torch.tensor([masked_idx])\n","            predicted_token_ids = torch.topk(predictions[0, masked_idx_tensor], 5).indices[0].tolist()\n","            predicted_tokens = self.tokenizer.convert_ids_to_tokens(predicted_token_ids)\n","            options = [masked_word]\n","            while len(options) < 4:\n","                random_word = self.get_random_word()\n","                if random_word not in options and random_word.isalpha():\n","                    options.append(random_word)\n","            random.shuffle(options)\n","            correct_index = options.index(masked_word)\n","            sentence_with_blank = self.tokenizer.convert_tokens_to_string(tokens).replace('[MASK]', '_______')\n","            mcq_questions_list.append([correct_index, sentence_with_blank, options])\n","        return mcq_questions_list"]},{"cell_type":"code","source":["passage = '''The old library, with its towering shelves and dim lighting, was a sanctuary for those who sought knowledge. Dusty books, filled with forgotten lore, lined every wall, their spines cracked and titles faded. In the heart of this literary maze, a young scholar named Anna spent her days immersed in study. She had a particular interest in ancient civilizations, pouring over texts that described lost cities and enigmatic cultures. One day, she stumbled upon a tome unlike any she had seen before. Its cover was adorned with intricate designs, and its pages were made of a material that felt almost otherworldly. As she delved into the book, she discovered it contained the secrets of a long-forgotten society, one that had mastered technologies far beyond the reach of modern science. Excited by her find, Anna decided to decipher the text, hoping to unlock the mysteries of the past. Days turned into weeks, and weeks into months, as she painstakingly translated the ancient script. The deeper she went, the more she realized the magnitude of her discovery. This was no ordinary society; it was a civilization that had thrived in harmony with nature, using sustainable practices that could revolutionize the present world. Her excitement grew with each revelation, and she knew she had to share her findings with the world. With her notes in hand, Anna prepared to publish her work, eager to enlighten others about the incredible wisdom of the ancients.'''\n","def main():\n","\n","    sentences = [sentence.strip() for sentence in passage.split('. ') if sentence]\n","\n","    qg = QuestionGenerator(passage)\n","\n","    # Generate fill-in-the-blank questions\n","    fill_in_the_blanks_questions = qg.generate_fill_in_the_blanks(sentences, num_questions=5)\n","    print(type(fill_in_the_blanks_questions))\n","    print(\"Fill-in-the-Blank Questions Dictionary:\")\n","    print(fill_in_the_blanks_questions)\n","\n","    # Generate MCQs\n","    mcq_questions = qg.generate_mcqs(sentences, num_questions=5)\n","    print(type(mcq_questions))\n","    print(\"\\nMultiple Choice Questions List of Lists:\")\n","    print(mcq_questions)"],"metadata":{"id":"3YU67WevbtCT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gdi39CJ1ceBS","executionInfo":{"status":"ok","timestamp":1717759543118,"user_tz":-300,"elapsed":29662,"user":{"displayName":"MUHAMMAD AHMED","userId":"14899745095089662324"}},"outputId":"f6472fca-3462-4b14-83db-1255d6c263ae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["<class 'dict'>\n","Fill-in-the-Blank Questions Dictionary:\n","{'the': 'excited by her find , anna decided to decipher the text , hoping to unlock the mysteries of *** past .', 'that': 'as she delved into the book , she discovered it contained the secrets of a long - forgotten society , one *** had mastered technologies far beyond the reach of modern science .', 'for': 'the old library , with its towering shelves and dim lighting , was a sanctuary *** those who sought knowledge .', 'lore': 'dusty books , filled with forgotten *** , lined every wall , their spines cracked and titles faded .', 'in': 'with her notes *** hand , anna prepared to publish her work , eager to enlighten others about the incredible wisdom of the ancients .'}\n","<class 'list'>\n","\n","Multiple Choice Questions List of Lists:\n","[[3, 'days turned into weeks , and weeks into months , as she painstakingly translated the _______ script .', ['Diplopoda', 'placentation', 'heavily', 'ancient']], [2, 'this was no ordinary society ; it was a civilization that had _______d in harmony with nature , using sustainable practices that could revolutionize the present world .', ['Megachile', 'false', 'thrive', 'chorale']], [2, 'she had a particular interest _______ ancient civilizations , pouring over texts that described lost cities and enigmatic cultures .', ['everyday', 'invalidated', 'in', 'myelography']], [0, 'as she delved into the book , she discovered it contained the secrets of a long - _______ society , one that had mastered technologies far beyond the reach of modern science .', ['forgotten', 'autocatalysis', 'surrejoinder', 'hydrochlorofluorocarbon']], [0, 'its cover was adorned with _______ designs , and its pages were made of a material that felt almost otherworldly .', ['intricate', 'Portunus', 'retribution', 'canary']]]\n"]}]}]}
